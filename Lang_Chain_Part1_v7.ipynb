{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidyasagarcrj/Codedirect/blob/main/Lang_Chain_Part1_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Requirements"
      ],
      "metadata": {
        "id": "Q1zp_cNzv1HT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_wDojnx_Kh8"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai langchain huggingface_hub --quiet\n",
        "!pip install cohere --quiet\n",
        "!pip install yfinance --quiet\n",
        "!pip install -U langchain-openai --quiet\n",
        "!pip install pytesseract  --quiet\n",
        "!pip install Pillow --quiet\n",
        "!pip install tesseract --quiet\n",
        "!apt install tesseract-ocr --quiet\n",
        "!apt install libtesseract-dev --quiet\n",
        "!pip install langchain_cohere\n",
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.llms import Cohere\n",
        "from langchain import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "import yfinance as yf\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "from IPython.display import Image as display_image"
      ],
      "metadata": {
        "id": "yh0jm2L3vsXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"Your own OPENAI_API_KEY\"\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"Your own HUGGINGFACEHUB_API_TOKEN\"\n",
        "os.environ['COHERE_API_KEY'] = \"Your own COHERE_API_KEY\"\n",
        "\n",
        "#Better way\n",
        "#from google.colab import userdata\n",
        "#os.environ['OPENAI_API_KEY'] = userdata.get(\"OPENAI_API_KEY\")\n",
        "#os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "#os.environ['COHERE_API_KEY'] = userdata.get(\"COHERE_API_KEY\")"
      ],
      "metadata": {
        "id": "hd6Wk8hYitJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLMS"
      ],
      "metadata": {
        "id": "SPrFjiRC_-n8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI model - Paid"
      ],
      "metadata": {
        "id": "s96e8yceAuF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm_openai=OpenAI(temperature=0.9, max_tokens=256)\n",
        "response = llm_openai.invoke(\"Write a 4 line poem on AI\")\n",
        "print(response)\n",
        "\n",
        "# - temperature: Set to 0.9, which controls the randomness of the output.\n",
        "#   A higher temperature results in more varied and unpredictable outputs,\n",
        "#   while a lower temperature produces more deterministic and conservative outputs.\n",
        "#   This is often used in generative tasks to balance between creativity and relevance.\n",
        "\n",
        "# - max_tokens: Set to 256, which specifies the maximum number of tokens (words or pieces of words)\n",
        "#   that the model can generate in a single response.\n",
        "\n",
        "\n",
        "llm_openai=OpenAI(temperature=0.9, max_tokens=256)\n"
      ],
      "metadata": {
        "id": "ulPawj03_9Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cohere - Opensource Alternative to OpenAI"
      ],
      "metadata": {
        "id": "vXI9Xg_XLIT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Cohere\n",
        "\n",
        "llm = Cohere(model=\"command-xlarge-nightly\")\n",
        "response = llm.invoke(\"Write a 4 line poem on AI\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Lcbo1bDQv9vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging face model - Free"
      ],
      "metadata": {
        "id": "QNqbovUnAxAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "#repo_id=\"openai-community/gpt2\"\n",
        "repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=repo_id,\n",
        "    model_kwargs={\"temperature\": 0.9, \"max_length\": 256},\n",
        ")\n",
        "\n",
        "response = llm.invoke(\"Write a 4 line poem on AI\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "BuvnmxzsAqgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Where LLMs fail"
      ],
      "metadata": {
        "id": "ZH61E66eQupw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAI(temperature=0, max_tokens=256)\n",
        "#llm=Cohere(model=\"command-xlarge-nightly\")\n",
        "\n",
        "response = llm.invoke(\"What is current market price of the Apple Stock?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "rce3pTdxQx2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Get the current market price of Apple stock\n",
        "apple_stock = yf.Ticker(\"AAPL\")\n",
        "apple_cmp= apple_stock.info[\"currentPrice\"]\n",
        "print(apple_cmp)"
      ],
      "metadata": {
        "id": "i17YnregRNlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Templates"
      ],
      "metadata": {
        "id": "Cdjz8TmFDdsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(\"Write a 4 line poem on AI\")\n",
        "response1 = llm.invoke(\"Craft a quartet of verses celebrating the marvels of artificial intelligence.\")\n",
        "response2 = llm.invoke(\"Compose a brief, ode to the wonders of AI.\")\n",
        "response3 = llm.invoke(\"Pen a short poem that captures the essence of artificial intelligence.\")\n",
        "response4 = llm.invoke(\"Create a succinct tribute to the advancements in AI.\")\n",
        "\n",
        "print(\"\\n======= response =======\\n\", response)\n",
        "print(\"\\n======= response1 =======\\n\", response1)\n",
        "print(\"\\n======= response2 =======\\n\", response2)\n",
        "print(\"\\n======= response3 =======\\n\", response3)\n",
        "print(\"\\n======= response4 =======\\n\", response4)"
      ],
      "metadata": {
        "id": "kyJ5AVrxiITF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"Write a 4 line poem on the subject {subject_name}\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"subject_name\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "print(prompt.format(subject_name=\"Data Science\"))\n",
        "print(prompt.format(subject_name=\"Fathers Day\"))\n",
        "print(prompt.format(subject_name=\"Solar System\"))"
      ],
      "metadata": {
        "id": "3Ktw2SS1Joo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Chain"
      ],
      "metadata": {
        "id": "wOqdJdanJkO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI, Cohere\n",
        "from langchain import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "#llm=OpenAI(temperature=0.1)\n",
        "llm=Cohere(temperature=0.1)\n",
        "\n",
        "template = \"List down the historically significant steps in the field of {filed_name}\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"filed_name\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "chain=LLMChain(llm=llm, prompt=prompt)\n",
        "#chian= prompt | llm\n",
        "result=chain.invoke(\"Machine Learning\")\n",
        "print(result['text'])"
      ],
      "metadata": {
        "id": "nKTNx5BNAqng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LAB: Example of an LLMChain"
      ],
      "metadata": {
        "id": "yYdIJ4unnlaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llm=OpenAI(temperature=0.9)\n",
        "llm=Cohere(temperature=0.9)\n",
        "\n",
        "template = \"The topic name is {topic}. Explain this topic to a 10 years old kid\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "chain=LLMChain(llm=llm, prompt=prompt)\n",
        "#chian= prompt | llm\n",
        "result=chain.invoke(\"Logistic Regression\")\n",
        "print(result['text'])\n"
      ],
      "metadata": {
        "id": "txWBdo4wnosh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chains"
      ],
      "metadata": {
        "id": "NpKFwWtcmGEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain1 : Finds the top10 books\n",
        "Find out the top ten books on any subject with this dedicated Chain."
      ],
      "metadata": {
        "id": "xmzHo7gtmgjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "#llm=OpenAI(temperature=0.5)\n",
        "llm=Cohere(temperature=0.5)\n",
        "\n",
        "book_name_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"theme\"],\n",
        "    template=\"\"\"Please provide a simple list of ten well-known\n",
        "                books that center around the theme of {theme}.\n",
        "                Do not include book description\"\"\"\n",
        ")\n",
        "\n",
        "book_name_chain = LLMChain(llm=llm,\n",
        "                           prompt=book_name_prompt_template,\n",
        "                           output_key=\"book_names_list\")\n",
        "#book_name_chain1=prompt | llm | {\"book_names_list\": StrOutputParser()}\n",
        "\n",
        "books_list = book_name_chain.invoke(input=\"personality development\")\n",
        "print(books_list[\"book_names_list\"])"
      ],
      "metadata": {
        "id": "Y97bObADmLLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain2 : Gives the summary\n",
        "\n",
        "This delivers a detailed summary for any specified book title."
      ],
      "metadata": {
        "id": "1T6S44lJo9Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llm=OpenAI(temperature=0.9, max_tokens=3000)\n",
        "llm=Cohere(temperature=0.9, max_tokens=3000)\n",
        "\n",
        "book_summary_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"book_names_list\"],\n",
        "    template=\"\"\"Please take any one book from the books list {book_names_list}.\n",
        "                Mention the book title.\n",
        "                Please provide a comprehensive summary of the book,in three sections\n",
        "                and each section with three summary points\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "book_summary_chain = LLMChain(llm=llm,\n",
        "                              prompt=book_summary_prompt_template,\n",
        "                              output_key=\"book_summary\")\n",
        "\n",
        "book_summary = book_summary_chain.invoke(input=\"The Catcher in the Rye by J.D. Salinger\")\n",
        "\n",
        "# Print the books\n",
        "print(book_summary['book_summary'])\n"
      ],
      "metadata": {
        "id": "izR7dLL4o_9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SequentialChain\n",
        "\n",
        "Takes theme as input. It first gets top 10 books from the given theme. Then it provides summary of any one of the top 10 books, without taking an specific input."
      ],
      "metadata": {
        "id": "9MMpptLcp2Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "book_chain = SequentialChain(\n",
        "    chains=[book_name_chain, book_summary_chain],\n",
        "    input_variables=[\"theme\"],\n",
        "    output_variables=[\"book_names_list\", \"book_summary\"]\n",
        "    )\n",
        "\n",
        "# Get the book summary for a specific book based on the theme\n",
        "book_summary = book_chain.invoke(input={\"theme\": \"Personal Finance\"})\n",
        "\n",
        "#print(book_summary)\n",
        "print(book_summary[\"book_summary\"])\n"
      ],
      "metadata": {
        "id": "axEQ8-zkp2bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAB : Sequential Chain"
      ],
      "metadata": {
        "id": "HlCAtKkk_4QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SBIN_Stock_Analysis = \"\"\"\n",
        "\n",
        "Company name is State Bank of India\n",
        "NSE Symbol is SBIN\n",
        "MARKET CAP - â‚¹ 6,69,078.16 Cr.\n",
        "Company has a good Return on Equity (ROE) track record: 3 Years ROE 13.46%.\n",
        "CASA stands at 42.67% of total deposits.\n",
        "The company has delivered good Profit growth of 51.35% over the past 3 years.\n",
        "Company has delivered good profit growth of 76.1% CAGR over last 5 years.\n",
        "Company has been maintaining a healthy dividend payout of 17.3%.\n",
        "Company's working capital requirements have reduced from 152 days to 118 days\n",
        "The bank has a very low ROA track record. Average ROA of 3 years is 0.70%.\n",
        "Low other Income proportion of 11.03%.High Cost to income ratio of 53.87%.\n",
        "Company has low interest coverage ratio.\n",
        "The company has delivered a poor sales growth of 8.91% over past five years.\n",
        "Company has a low return on equity of 12.8% over last 3 years.\n",
        "Contingent liabilities of Rs.19,00,096 Cr.\n",
        "Company might be capitalizing the interest cost.\n",
        "Earnings include an other income of Rs.1,39,611 Cr.\n",
        "\n",
        "\"\"\"\n",
        "print(SBIN_Stock_Analysis)"
      ],
      "metadata": {
        "id": "w6WFeafSgU3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain1 : Positives and Negatives"
      ],
      "metadata": {
        "id": "E8gZP_4cxemV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llm=OpenAI(temperature=0, max_tokens=256)\n",
        "llm=Cohere(temperature=0, max_tokens=256)\n",
        "\n",
        "template =\"\"\"Read the text data from {stock_analysis_input}.\n",
        "              Mention the company name and marekt capital.\n",
        "              Write top3 positive and top3 negative points.\n",
        "              keep the points short\"\"\"\n",
        "\n",
        "information_extraction_prompt = PromptTemplate(\n",
        "    input_variables=[\"stock_analysis_input\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "#print(information_extraction_prompt.format(stock_analysis_input=SBIN_Stock_Analysis))\n",
        "\n",
        "information_extraction_chain=LLMChain( llm=llm,\n",
        "                                       prompt=information_extraction_prompt,\n",
        "                                       output_key=\"Pros_and_Cons\")\n",
        "\n",
        "result=information_extraction_chain.invoke(SBIN_Stock_Analysis)\n",
        "#print(result.keys())\n",
        "print(result['Pros_and_Cons'])"
      ],
      "metadata": {
        "id": "Z8lf7Rlxhy94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain2 : Investor Report"
      ],
      "metadata": {
        "id": "o7bpvCIuzHIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llm=OpenAI(temperature=0, max_tokens=256)\n",
        "llm=Cohere(temperature=0, max_tokens=256)\n",
        "\n",
        "template =\"\"\"\n",
        "Imagine you've been analyzing stocks for over 15 years.\n",
        "Look at the good and bad points, and see if the company can grow.\n",
        "Right now, is buying shares of this company a smart move?\n",
        "take the data from {Pros_and_Cons}\n",
        "\"\"\"\n",
        "\n",
        "stock_decision_prompt = PromptTemplate(\n",
        "    input_variables=[\"Pros_and_Cons\"],\n",
        "    template=template,\n",
        ")\n",
        "#print(stock_decision_prompt.format(Pros_and_Cons=result['Pros_and_Cons']))\n",
        "\n",
        "stock_decision_chain=LLMChain(llm=llm,\n",
        "                              prompt=stock_decision_prompt,\n",
        "                              output_key=\"Investor_Report\")\n",
        "result=stock_decision_chain.invoke(SBIN_Stock_Analysis)\n",
        "print(result['Investor_Report'])"
      ],
      "metadata": {
        "id": "xcz523mpjtTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Sequential Chain\n"
      ],
      "metadata": {
        "id": "vgu8E8j7vgJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain=SequentialChain(chains=[information_extraction_chain, stock_decision_chain],\n",
        "                           input_variables=[\"stock_analysis_input\"],\n",
        "                           output_variables=[\"Pros_and_Cons\", \"Investor_Report\"])\n",
        "result=full_chain.invoke(SBIN_Stock_Analysis)\n",
        "print(result[\"Investor_Report\"])"
      ],
      "metadata": {
        "id": "ILIEcnASumbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain + IDP (Intelligent Document Processing)"
      ],
      "metadata": {
        "id": "DEg7_WB4vIs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the Images, try Invoice_1.png, Invoice_2.png, Invoice_3.png, Invoice_4.png\n",
        "#Try different images in this example\n",
        "!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/IDM_Datasets/Invoices/Invoice_1.png\n",
        "!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/IDM_Datasets/Invoices/Invoice_2.png\n",
        "!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/IDM_Datasets/Invoices/Invoice_3.png\n",
        "!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/IDM_Datasets/Invoices/Invoice_4.png\n",
        "\n",
        "\n",
        "image_path=image_path = '/content/Invoice_4.png'\n",
        "display_image(filename=image_path)"
      ],
      "metadata": {
        "id": "2sTIZmVIvoq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IDP without LLM"
      ],
      "metadata": {
        "id": "Zw6LrPNnJUGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import re\n",
        "\n",
        "def extract_email_addresses(image_path):\n",
        "    text = pytesseract.image_to_string(image_path)\n",
        "    email_addresses = re.findall(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
        "    # Regular expression to match dates in DD/MM/YYYY, DD-MM-YYYY, or YYYY-MM-DD formats\n",
        "    dob_patterns = re.findall(r\"\\b(?:\\d{2}[/-]\\d{2}[/-]\\d{4}|\\d{4}[/-]\\d{2}[/-]\\d{2})\\b\", text)\n",
        "    print(\"Email Address: \", email_addresses)\n",
        "    return"
      ],
      "metadata": {
        "id": "yf7eqPtWJTeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_email_addresses(image_path)"
      ],
      "metadata": {
        "id": "GI4GvX5KJaxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IDP with LLMs"
      ],
      "metadata": {
        "id": "QpRelZc7Kj0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract Text from Image\n",
        "img = Image.open(image_path)\n",
        "invoice_text = pytesseract.image_to_string(img)\n",
        "#print(invoice_text)\n",
        "\n",
        "#llm=OpenAI(temperature=0)\n",
        "llm=Cohere(temperature=0)\n",
        "\n",
        "template=\"\"\"\n",
        "Take the information from {invoice_text} and print the itemwise price and quantity.\n",
        "\"\"\"\n",
        "\n",
        "invoice_prompt = PromptTemplate(\n",
        "    input_variables=[\"invoice_text\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "invoice_chain=LLMChain(llm=llm, prompt=invoice_prompt, output_key=\"itemwise_price_and_quantity\")\n",
        "result=invoice_chain.invoke(invoice_text)\n",
        "print(result['itemwise_price_and_quantity'])"
      ],
      "metadata": {
        "id": "-0nvlhLEvS9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display_markdown\n",
        "\n",
        "result_values=result['itemwise_price_and_quantity']\n",
        "display_markdown(result_values, raw=True)"
      ],
      "metadata": {
        "id": "tPqOGrEVGjAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template=\"\"\"\n",
        "Take the information from {invoice_text} and print the client name,phone number, email and total amout\n",
        "\"\"\"\n",
        "\n",
        "invoice_prompt = PromptTemplate(\n",
        "    input_variables=[\"invoice_text\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "invoice_chain=LLMChain(llm=llm, prompt=invoice_prompt, output_key=\"contact_details\")\n",
        "result=invoice_chain.invoke(invoice_text)\n",
        "print(result['contact_details'])"
      ],
      "metadata": {
        "id": "VWa8CX4Y0cfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template=\"\"\"\n",
        "Take the information from {invoice_text} and print the bank account number and payment conditions\n",
        "\"\"\"\n",
        "\n",
        "invoice_prompt = PromptTemplate(\n",
        "    input_variables=[\"invoice_text\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "invoice_chain=LLMChain(llm=llm, prompt=invoice_prompt, output_key=\"bank_details\")\n",
        "result=invoice_chain.invoke(invoice_text)\n",
        "print(result['bank_details'])"
      ],
      "metadata": {
        "id": "qqBFd1tK2D6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment - Book Summary App"
      ],
      "metadata": {
        "id": "KQkMLUrfY3qR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3vLanZ2Sov6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}